{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lesson 4: Chaining Prompts for Agentic Reasoning\n",
        "\n",
        "## Automated Claim Triage: From First-Notice to the Right Queue\n",
        "\n",
        "In this hands-on exercise, you will build a prompt chain that extracts key fields from free-form auto-claim reports, assesses damage severity, and routes each claim to one of several queues ‚Äî `glass`, `fast_track`, `material_damage`, or `total_loss` ‚Äî with code-based gate checks at every step.\n",
        "\n",
        "## Outline:\n",
        "\n",
        "- Setup\n",
        "- Sample FNOL (First Notice of Loss) Texts\n",
        "- Stage I: Information Extraction\n",
        "- Stage II: Severity Assessment\n",
        "- Stage III: Queue Routing\n",
        "- Review Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Import necessary libraries and define helper functions, including a mock LLM client, code execution environment, and test runner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "# No changes needed in this cell\n",
        "from openai import OpenAI  # For accessing the OpenAI API\n",
        "from enum import Enum\n",
        "import json\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pydantic import BaseModel, Field  # For structured data validation\n",
        "from typing import List, Literal, Optional\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up LLM credentials\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openai.vocareum.com/v1\",\n",
        "    # Uncomment one of the following\n",
        "    api_key=os.getenv(\n",
        "        \"OPENAI_API_KEY\"\n",
        "    ),  # <-- Alternately, set as an environment variable\n",
        ")\n",
        "\n",
        "# If using OpenAI's API endpoint\n",
        "# client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define helper functions\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "class OpenAIModels(str, Enum):\n",
        "    GPT_4O_MINI = \"gpt-4o-mini\"\n",
        "    GPT_41_MINI = \"gpt-4.1-mini\"\n",
        "    GPT_41_NANO = \"gpt-4.1-nano\"\n",
        "\n",
        "\n",
        "MODEL = OpenAIModels.GPT_41_NANO\n",
        "\n",
        "\n",
        "def get_completion(messages=None, system_prompt=None, user_prompt=None, model=MODEL):\n",
        "    \"\"\"\n",
        "    Function to get a completion from the OpenAI API.\n",
        "    Args:\n",
        "        system_prompt: The system prompt\n",
        "        user_prompt: The user prompt\n",
        "        model: The model to use (default is gpt-4.1-mini)\n",
        "    Returns:\n",
        "        The completion text\n",
        "    \"\"\"\n",
        "\n",
        "    messages = list(messages)\n",
        "    if system_prompt:\n",
        "        messages.insert(0, {\"role\": \"system\", \"content\": system_prompt})\n",
        "    if user_prompt:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample FNOL (First Notice of Loss) Texts\n",
        "Let's define a few sample First Notice of Loss (FNOL) texts to process through our chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define sample FNOL texts\n",
        "# TODO: [Optional] Add more sample FNOL texts to test various scenarios\n",
        "\n",
        "sample_fnols = [\n",
        "    \"\"\"\n",
        "    Claim ID: C001\n",
        "    Customer: John Smith\n",
        "    Vehicle: 2018 Toyota Camry\n",
        "    Incident: While driving on the highway, a rock hit my windshield and caused a small chip\n",
        "    about the size of a quarter. No other damage was observed.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Claim ID: C002\n",
        "    Customer: Sarah Johnson\n",
        "    Vehicle: 2020 Honda Civic\n",
        "    Incident: I was parked at the grocery store and returned to find someone had hit my car and\n",
        "    dented the rear bumper and taillight. The taillight is broken and the bumper has a large dent.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Claim ID: C003\n",
        "    Customer: Michael Rodriguez\n",
        "    Vehicle: 2022 Ford F-150\n",
        "    Incident: I was involved in a serious collision at an intersection. The front of my truck is\n",
        "    severely damaged, including the hood, bumper, radiator, and engine compartment. The airbags\n",
        "    deployed and the vehicle is not drivable.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Claim ID: C004\n",
        "    Customer: Emma Williams\n",
        "    Vehicle: 2019 Subaru Outback\n",
        "    Incident: My car was damaged in a hailstorm. There are multiple dents on the hood, roof, and\n",
        "    trunk. The side mirrors were also damaged and one window has a small crack.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Claim ID: C005\n",
        "    Customer: David Brown\n",
        "    Vehicle: 2021 Tesla Model 3\n",
        "    Incident: Someone keyed my car in the parking lot. There are deep scratches along both doors\n",
        "    on the driver's side.\n",
        "    \"\"\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stage I: Information Extraction\n",
        "In this stage, we'll create a prompt that extracts structured information from free-form FNOL text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a system prompt for information extraction according to the provided ClaimInformation class\n",
        "# TODO: Complete the prompt by replacing the parts marked with **********\n",
        "\n",
        "\n",
        "class ClaimInformation(BaseModel):\n",
        "    claim_id: str = Field(..., min_length=2, max_length=10)\n",
        "    name: str = Field(..., min_length=2, max_length=100)\n",
        "    vehicle: str = Field(..., min_length=2, max_length=100)\n",
        "    loss_desc: str = Field(..., min_length=10, max_length=500)\n",
        "    damage_area: List[\n",
        "        Literal[\n",
        "            \"windshield\",\n",
        "            \"front\",\n",
        "            \"rear\",\n",
        "            \"side\",\n",
        "            \"roof\",\n",
        "            \"hood\",\n",
        "            \"door\",\n",
        "            \"bumper\",\n",
        "            \"fender\",\n",
        "            \"quarter panel\",\n",
        "            \"trunk\",\n",
        "            \"glass\",\n",
        "        ]\n",
        "    ] = Field(..., min_items=1)\n",
        "\n",
        "\n",
        "info_extraction_system_prompt = \"\"\"\n",
        "You are an auto insurance claim processing assistant. Your task is to extract key information from First Notice of Loss (FNOL) reports.\n",
        "\n",
        "Format your response as a valid JSON object with the following keys:\n",
        "- claim_id (str): The claim ID\n",
        "- name (str): The customer's full name\n",
        "- vehicle (str): The vehicle make, model, and year\n",
        "- loss_desc (str): A concise description of the incident\n",
        "- damage_area (list[str]): A list of damaged areas on the vehicle (at least one of:\n",
        "    - windshield\n",
        "    - front\n",
        "    - rear\n",
        "    - side\n",
        "    - roof\n",
        "    - hood\n",
        "    - door\n",
        "    - bumper\n",
        "    - fender\n",
        "    - quarter panel\n",
        "    - trunk\n",
        "    - glass\n",
        "\n",
        "For damage_area, only use items from the list above.\n",
        "\n",
        "Only respond with the JSON object, nothing else.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a gate check function and claim extraction function\n",
        "# TODO: Complete the prompt by replacing the parts marked with **********\n",
        "\n",
        "\n",
        "def gate1_validate_claim_info(claim_info_json: str) -> ClaimInformation:\n",
        "    \"\"\"\n",
        "    Gate 1: Validates claim information extracted from FNOL text.\n",
        "    Returns validated ClaimInformation object or raises validation error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse the JSON string\n",
        "        claim_info_dict = json.loads(claim_info_json)\n",
        "        # Validate with Pydantic model\n",
        "        validated_info = ClaimInformation(**claim_info_dict)\n",
        "        return validated_info\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Gate 1 validation failed: {str(e)}\")\n",
        "\n",
        "\n",
        "def extract_claim_info(fnol_text):\n",
        "    \"\"\"\n",
        "    Stage 1: Extract structured information from FNOL text\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": info_extraction_system_prompt},\n",
        "        {\"role\": \"user\", \"content\": fnol_text},\n",
        "    ]\n",
        "\n",
        "    response = get_completion(messages=messages)\n",
        "\n",
        "    # Gate check: validate the extracted information\n",
        "    try:\n",
        "        validated_info = gate1_validate_claim_info(response)\n",
        "        return validated_info\n",
        "    except ValueError as e:\n",
        "        print(f\"Gate 1 failed: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ClaimInformation(claim_id='C001', name='John Smith', vehicle='2018 Toyota Camry', loss_desc='Rock hit windshield causing a small chip', damage_area=['windshield']),\n",
              " ClaimInformation(claim_id='C002', name='Sarah Johnson', vehicle='2020 Honda Civic', loss_desc='Someone hit the parked car, denting the rear bumper and breaking the taillight.', damage_area=['bumper', 'rear']),\n",
              " ClaimInformation(claim_id='C003', name='Michael Rodriguez', vehicle='2022 Ford F-150', loss_desc='Serious collision at intersection with front damage and airbags deployed', damage_area=['front', 'hood', 'bumper']),\n",
              " ClaimInformation(claim_id='C004', name='Emma Williams', vehicle='2019 Subaru Outback', loss_desc='Hailstorm caused dents on hood, roof, trunk, damage to side mirrors, and a crack on one window.', damage_area=['roof', 'hood', 'trunk', 'side', 'glass']),\n",
              " ClaimInformation(claim_id='C005', name='David Brown', vehicle='2021 Tesla Model 3', loss_desc=\"Someone keyed the car in the parking lot, causing deep scratches along both doors on the driver's side.\", damage_area=['door'])]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run the claim extraction function on the sample FNOLs\n",
        "# No updates needed in this cell\n",
        "\n",
        "extracted_claim_info_items = [\n",
        "    extract_claim_info(fnol_text) for fnol_text in sample_fnols\n",
        "]\n",
        "extracted_claim_info_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stage II: Severity Assessment\n",
        "In this stage, we'll assess the severity of the damage based on the extracted information.\n",
        "\n",
        "Note, our carrier applies the following heuristics:\n",
        "- Minor damage: Small dents, scratches, glass chips (cost range: $100-$1,000)\n",
        "- Moderate damage: Single panel damage, bumper replacement, door damage (cost range: $1,000-$5,000)\n",
        "- Major damage: Structural damage, multiple panel replacement, engine/drivetrain issues, total loss candidates (cost range: $5,000-$50,000)\n",
        "\n",
        "In this example we will let the LLM estimate the cost, though in production we would want a more accurate estimate, e.g. querying a database of repair costs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a system prompt for severity assessment according to the provided SeverityAssessment class\n",
        "# TODO: Complete the prompt by replacing the parts marked with **********\n",
        "\n",
        "\n",
        "class SeverityAssessment(BaseModel):\n",
        "    severity: Literal[\"Minor\", \"Moderate\", \"Major\"]\n",
        "    est_cost: float = Field(..., gt=0)\n",
        "\n",
        "\n",
        "severity_assessment_system_prompt = \"\"\"\n",
        "You are an auto insurance damage assessor. Your task is to evaluate the severity of vehicle damage and estimate repair costs.\n",
        "\n",
        "Apply these carrier heuristics:\n",
        "- Minor damage: Small dents, scratches, glass chips (cost range: $100-$1,000)\n",
        "- Moderate damage: Single panel damage, bumper replacement, door damage (cost range: $1,000-$5,000)\n",
        "- Major damage: Structural damage, multiple panel replacement, engine/drivetrain issues, total loss candidates (cost range: $5,000-$50,000)\n",
        "\n",
        "Based on the claim information provided, determine:\n",
        "1. Severity level (Minor, Moderate, or Major)\n",
        "2. Estimated repair cost (in USD)\n",
        "\n",
        "Format your response as a valid JSON object with the following keys:\n",
        "- severity: One of \"Minor\", \"Moderate\", or \"Major\"\n",
        "- est_cost: Numeric estimate of repair costs (e.g., 750.00)\n",
        "\n",
        "Only respond with the JSON object, nothing else.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a gate check function and assess_severity function\n",
        "# TODO: Complete the prompt by replacing the parts marked with **********\n",
        "\n",
        "\n",
        "def gate2_cost_range_ok(severity_json: str) -> SeverityAssessment:\n",
        "    \"\"\"\n",
        "    Gate 2: Validates that the estimated cost is within reasonable range for the severity.\n",
        "    Returns validated SeverityAssessment object or raises validation error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse the JSON string\n",
        "        severity_dict = json.loads(severity_json)\n",
        "        # Validate with Pydantic model\n",
        "        validated_severity = SeverityAssessment(**severity_dict)\n",
        "\n",
        "        # Check cost range based on severity\n",
        "        if validated_severity.severity == \"Minor\" and (\n",
        "            validated_severity.est_cost < 100 or validated_severity.est_cost > 1000\n",
        "        ):\n",
        "            raise ValueError(\n",
        "                f\"Minor damage should cost between $100-$1000, got ${validated_severity.est_cost}\"\n",
        "            )\n",
        "        elif validated_severity.severity == \"Moderate\" and (\n",
        "            validated_severity.est_cost < 1000 or validated_severity.est_cost > 5000\n",
        "        ):\n",
        "            raise ValueError(\n",
        "                f\"Moderate damage should cost between $1000-$5000, got ${validated_severity.est_cost}\"\n",
        "            )\n",
        "        elif validated_severity.severity == \"Major\" and (\n",
        "            validated_severity.est_cost < 5000 or validated_severity.est_cost > 50000\n",
        "        ):\n",
        "            raise ValueError(\n",
        "                f\"Major damage should cost between $5000-$50000, got ${validated_severity.est_cost}\"\n",
        "            )\n",
        "\n",
        "        return validated_severity\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Gate 2 validation failed: {str(e)}\")\n",
        "\n",
        "\n",
        "def assess_severity(claim_info: ClaimInformation) -> Optional[SeverityAssessment]:\n",
        "    \"\"\"\n",
        "    Stage 2: Assess severity based on damage description\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert Pydantic model to JSON string\n",
        "    claim_info_json = claim_info.model_dump_json()\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": severity_assessment_system_prompt},\n",
        "        {\"role\": \"user\", \"content\": claim_info_json},\n",
        "    ]\n",
        "\n",
        "    response = get_completion(messages=messages)\n",
        "\n",
        "    # Gate check: validate the severity assessment\n",
        "    try:\n",
        "        validated_severity = gate2_cost_range_ok(response)\n",
        "        return validated_severity\n",
        "    except ValueError as e:\n",
        "        print(f\"Gate 2 failed: {e}. Response: {response}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SeverityAssessment(severity='Minor', est_cost=200.0),\n",
              " SeverityAssessment(severity='Moderate', est_cost=2000.0),\n",
              " SeverityAssessment(severity='Major', est_cost=15000.0),\n",
              " SeverityAssessment(severity='Moderate', est_cost=3500.0),\n",
              " SeverityAssessment(severity='Moderate', est_cost=2000.0)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run the claim extraction function on the sample data\n",
        "# No updates needed in this cell\n",
        "\n",
        "severity_assessment_items = [\n",
        "    assess_severity(item) for item in extracted_claim_info_items\n",
        "]\n",
        "\n",
        "severity_assessment_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stage III: Queue Routing\n",
        "In this stage, we'll route the claim to the appropriate queue based on severity and damage area.\n",
        "\n",
        "Use these routing rules:\n",
        "- 'glass' queue: For Minor damage involving ONLY glass (windshield, windows)\n",
        "- 'fast_track' queue: For other Minor damage\n",
        "- 'material_damage' queue: For all Moderate damage\n",
        "- 'total_loss' queue: For all Major damage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a system prompt for claim routing according to the provided ClaimRouting class\n",
        "# TODO: Complete the prompt by replacing the parts marked with **********\n",
        "\n",
        "\n",
        "class ClaimRouting(BaseModel):\n",
        "    claim_id: str\n",
        "    queue: Literal[\"glass\", \"fast_track\", \"material_damage\", \"total_loss\"]\n",
        "\n",
        "\n",
        "queue_routing_system_prompt = \"\"\"\n",
        "You are an auto insurance claim routing specialist. Your task is to determine the appropriate processing queue for each claim.\n",
        "\n",
        "Use these routing rules:\n",
        "- 'glass' queue: For Minor damage involving ONLY glass (windshield, windows)\n",
        "- 'fast_track' queue: For other Minor damage\n",
        "- 'material_damage' queue: For all Moderate damage\n",
        "- 'total_loss' queue: For all Major damage\n",
        "\n",
        "Format your response as a valid JSON object with the following keys:\n",
        "- claim_id: Use the provided claim ID\n",
        "- queue: One of \"glass\", \"fast_track\", \"material_damage\", or \"total_loss\"\n",
        "\n",
        "Only respond with the JSON object, nothing else.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a gate check function and assess_severity function\n",
        "# TODO: Complete the prompt by replacing the parts marked with **********\n",
        "\n",
        "\n",
        "def gate3_validate_routing(routing_json: str) -> ClaimRouting:\n",
        "    \"\"\"\n",
        "    Gate 3: Validates that the claim is routed to a valid queue.\n",
        "    Returns validated ClaimRouting object or raises validation error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse the JSON string\n",
        "        routing_dict = json.loads(routing_json)\n",
        "        # Validate with Pydantic model\n",
        "        validated_routing = ClaimRouting(**routing_dict)\n",
        "        return validated_routing\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Gate 3 validation failed: {str(e)}\")\n",
        "\n",
        "\n",
        "def route_claim(\n",
        "    claim_info: ClaimInformation, severity_assessment: Optional[SeverityAssessment]\n",
        ") -> Optional[ClaimRouting]:\n",
        "    \"\"\"\n",
        "    Stage 3: Route claim to appropriate queue\n",
        "    \"\"\"\n",
        "    if severity_assessment is None:\n",
        "        return None\n",
        "\n",
        "    # Create input for the routing model\n",
        "    routing_input = {\n",
        "        \"claim_info\": claim_info.model_dump(),\n",
        "        \"severity_assessment\": severity_assessment.model_dump(),\n",
        "    }\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": queue_routing_system_prompt},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(routing_input)},\n",
        "    ]\n",
        "\n",
        "    response = get_completion(messages=messages)\n",
        "\n",
        "    # Gate check: validate the routing decision\n",
        "    try:\n",
        "        validated_routing = gate3_validate_routing(response)\n",
        "        return validated_routing\n",
        "    except ValueError as e:\n",
        "        print(f\"Gate 3 failed: {e}. Response: {response}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ClaimRouting(claim_id='C001', queue='glass'),\n",
              " ClaimRouting(claim_id='C002', queue='material_damage'),\n",
              " ClaimRouting(claim_id='C003', queue='total_loss'),\n",
              " ClaimRouting(claim_id='C004', queue='material_damage'),\n",
              " ClaimRouting(claim_id='C005', queue='material_damage')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run the routing function on the sample data\n",
        "# No updates needed in this cell\n",
        "\n",
        "routed_claim_items = [\n",
        "    route_claim(claim, severity_assessment)\n",
        "    for claim, severity_assessment in zip(\n",
        "        extracted_claim_info_items, severity_assessment_items\n",
        "    )\n",
        "]\n",
        "\n",
        "routed_claim_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review Outputs\n",
        "\n",
        "Let's put our data into a pandas dataframe for easier analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim_id</th>\n",
              "      <th>name</th>\n",
              "      <th>vehicle</th>\n",
              "      <th>loss_desc</th>\n",
              "      <th>damage_area</th>\n",
              "      <th>severity</th>\n",
              "      <th>est_cost</th>\n",
              "      <th>queue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C001</td>\n",
              "      <td>John Smith</td>\n",
              "      <td>2018 Toyota Camry</td>\n",
              "      <td>Rock hit windshield causing a small chip</td>\n",
              "      <td>[windshield]</td>\n",
              "      <td>Minor</td>\n",
              "      <td>200.0</td>\n",
              "      <td>glass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C002</td>\n",
              "      <td>Sarah Johnson</td>\n",
              "      <td>2020 Honda Civic</td>\n",
              "      <td>Someone hit the parked car, denting the rear bumper and breaking the taillight.</td>\n",
              "      <td>[bumper, rear]</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>material_damage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C003</td>\n",
              "      <td>Michael Rodriguez</td>\n",
              "      <td>2022 Ford F-150</td>\n",
              "      <td>Serious collision at intersection with front damage and airbags deployed</td>\n",
              "      <td>[front, hood, bumper]</td>\n",
              "      <td>Major</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>total_loss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C004</td>\n",
              "      <td>Emma Williams</td>\n",
              "      <td>2019 Subaru Outback</td>\n",
              "      <td>Hailstorm caused dents on hood, roof, trunk, damage to side mirrors, and a crack on one window.</td>\n",
              "      <td>[roof, hood, trunk, side, glass]</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>3500.0</td>\n",
              "      <td>material_damage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C005</td>\n",
              "      <td>David Brown</td>\n",
              "      <td>2021 Tesla Model 3</td>\n",
              "      <td>Someone keyed the car in the parking lot, causing deep scratches along both doors on the driver's side.</td>\n",
              "      <td>[door]</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>material_damage</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  claim_id               name              vehicle  \\\n",
              "0     C001         John Smith    2018 Toyota Camry   \n",
              "1     C002      Sarah Johnson     2020 Honda Civic   \n",
              "2     C003  Michael Rodriguez      2022 Ford F-150   \n",
              "3     C004      Emma Williams  2019 Subaru Outback   \n",
              "4     C005        David Brown   2021 Tesla Model 3   \n",
              "\n",
              "                                                                                                 loss_desc  \\\n",
              "0                                                                 Rock hit windshield causing a small chip   \n",
              "1                          Someone hit the parked car, denting the rear bumper and breaking the taillight.   \n",
              "2                                 Serious collision at intersection with front damage and airbags deployed   \n",
              "3          Hailstorm caused dents on hood, roof, trunk, damage to side mirrors, and a crack on one window.   \n",
              "4  Someone keyed the car in the parking lot, causing deep scratches along both doors on the driver's side.   \n",
              "\n",
              "                        damage_area  severity  est_cost            queue  \n",
              "0                      [windshield]     Minor     200.0            glass  \n",
              "1                    [bumper, rear]  Moderate    2000.0  material_damage  \n",
              "2             [front, hood, bumper]     Major   15000.0       total_loss  \n",
              "3  [roof, hood, trunk, side, glass]  Moderate    3500.0  material_damage  \n",
              "4                            [door]  Moderate    2000.0  material_damage  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# No updates needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "records = []\n",
        "for claim, severity_assessment, routed_claim in zip(\n",
        "    extracted_claim_info_items, severity_assessment_items, routed_claim_items\n",
        "):\n",
        "    record = {}\n",
        "    record.update(claim)\n",
        "    record.update(severity_assessment)\n",
        "    record.update(routed_claim)\n",
        "    records.append(record)\n",
        "\n",
        "\n",
        "# Show the entire dataframe since it is not too large\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "üéâ Congratulations! üéâ You've built an impressive prompt chain system for insurance claims!\n",
        "You transformed messy FNOL text into structured data, assessed damage severity, and routed claims to the right queues, all with robust gate checks! üöÄ‚ú®\n",
        "\n",
        "Remember:\n",
        "\n",
        "- üîó Chained prompts break complex tasks into manageable steps\n",
        "- üõ°Ô∏è Gate checks prevent error cascades\n",
        "- üß† Having specialized prompts helps keep code focused and maintainable\n",
        "\n",
        "You've mastered a powerful pattern for countless business processes! üèÜ\n",
        "Amazing work on your agentic reasoning system! üíØ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "agentic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
